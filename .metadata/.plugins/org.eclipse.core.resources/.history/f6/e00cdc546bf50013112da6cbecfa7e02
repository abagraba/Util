package com.mimvista.cloud.server.filestore;

import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.net.MalformedURLException;
import java.net.URL;
import java.net.URLEncoder;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.logging.Level;
import java.util.logging.Logger;

import com.google.appengine.api.urlfetch.HTTPHeader;
import com.google.appengine.api.urlfetch.HTTPMethod;
import com.google.appengine.api.urlfetch.HTTPRequest;
import com.google.appengine.api.urlfetch.HTTPResponse;
import com.google.appengine.api.urlfetch.URLFetchServiceFactory;
import com.google.common.collect.Lists;
import com.google.gdata.util.common.base.Pair;
import com.mimvista.cloud.models.Series;
import com.mimvista.cloud.server.DAO;
import com.mimvista.cloud.server.SadfoxServerContext;
import com.mimvista.cloud.server.upload.S3PolicyGenerator;
import com.mimvista.cloud.shared.common.enums.StudyEnums.S3Location;

/*
 * Package-private, since we don't want ppl directly instantiating these (breaks testability)
 */
class S3ServiceImpl extends S3Service {

	private static final int DELETE_RESPONSE_CODE = 204;
	private static final long HALF_HOUR_MILLIS = 30l*60l*1000l;
	private static final long ONE_HOUR_MILLIS = HALF_HOUR_MILLIS*2;
	private static final long GET_URL_EXPIRATION_MILLIS = ONE_HOUR_MILLIS*4; // 4 hours
	private static final long HEAD_DELETE_EXPIRATION_MILLIS = ONE_HOUR_MILLIS*4; // 4 hours (stupid clockdrift)
	private static final double TIMEOUT_SECONDS = 60.0;	// 60 sec is max on appegine
	private static final Logger log = Logger.getLogger(S3ServiceImpl.class.getName());
	
	@Override
	public boolean checkFileExists(S3Location loc, String key) {
		long size = checkFileSizeOnS3(loc, key);
		return size > 0;
	}

	public long checkFileSizeOnS3(S3Location loc, String key) {
		try{
			HTTPRequest req = createExistsRequest(loc, key);
			HTTPResponse fetch = URLFetchServiceFactory.getURLFetchService().fetch(req);
			long sizeFromHeader = getSizeFromHeader(fetch);
			return sizeFromHeader;
		}catch(Exception e){
			return -1L;
		}
	}

	private long getSizeFromHeader(HTTPResponse rsp){
		int responseCode = rsp.getResponseCode();
		if(responseCode < 200 || responseCode > 299){
			return -1L;
		}
		List<HTTPHeader> headers = rsp.getHeaders();
		for(HTTPHeader header : headers){
			if(responseCode == 200 && "Content-Length".equalsIgnoreCase(header.getName())){
				long parseLong = Long.parseLong(header.getValue());
				return parseLong;
			}
			if (responseCode == 206 && "Content-Range".equalsIgnoreCase(header.getName())) {
				long parseLong = Long.parseLong(header.getValue().substring(header.getValue().lastIndexOf('/') + 1));
				return parseLong;
			}
		}
		return -1L;
	}

	@Override
	// XXX: possibly want to verify file existence before returning to user...
	public String getDownloadUrl(S3Location loc, String key) {
		return generateURL("GET", loc.getBucket(SadfoxServerContext.domainContext), key, GET_URL_EXPIRATION_MILLIS);
	}

	@Override
	public String getHeadUrl(S3Location loc, String key) {
		// TODO Auto-generated method stub
		return null;
	}
	
	@Override
	/*
	 * DELETEs should expect a 204 No Content response.
	 */
	public void delete(S3Location loc, String key) {
		if (DAO.MIGRATION_MODE){
			throw new RuntimeException("No deletes for now, plz");
		}
		// If the S3Location is null, simply return because the series does not exist on S3, so it can't be deleted.
		if (loc == null) {
			log.log(Level.WARNING, "Attempting to delete series with null S3 location. Key: " + key);
			return;
		}
		
		HTTPRequest req = createDeleteRequest(loc, key);
		if (!verifyRequest(DELETE_RESPONSE_CODE, req)) {
			throw new RuntimeException("Error communicating with S3 to delete file!");
		}
	}

	@Override
	public boolean checkFilesExist(Series... series) {
		return newAsyncExistenceClient(series).waitFinalResult();
	}

	private HTTPRequest createExistsRequest(S3Location loc, String key) {
		String url = generateURL("GET", loc.getBucket(SadfoxServerContext.domainContext), key, HEAD_DELETE_EXPIRATION_MILLIS);
		HTTPRequest req = createRequest(HTTPMethod.GET, url);
		req.addHeader(new HTTPHeader("Range", "bytes=0-100"));
		return req;
	}

	private HTTPRequest createDeleteRequest(S3Location loc, String key) {
		if (DAO.MIGRATION_MODE){
			throw new RuntimeException("No deletes for now, plz");
		}
		if (SadfoxServerContext.domainContext.isMigratoryMimu())
			throw new RuntimeException("trying to delete from the migrator?!");
		
		// If the S3Location is null, simply return because the series does not exist on S3, so it can't be deleted.
		if (loc == null) {
			log.log(Level.WARNING, "Attempting to delete series with null S3 location. Key: " + key);
			return null;
		}
		
		String url = generateURL("DELETE", loc.getBucket(SadfoxServerContext.domainContext), key, HEAD_DELETE_EXPIRATION_MILLIS);
		HTTPRequest req = createRequest(HTTPMethod.DELETE, url);
		return req;
	}

	private HTTPRequest createCopyRequest(S3Location loc, String srcKey, String destKey) {
		String bucket = loc.getBucket(SadfoxServerContext.domainContext);
		String url = "http://" + bucket + ".s3.amazonaws.com/" + destKey;
		HTTPRequest req = createRequest(HTTPMethod.PUT, url);

		String copySource = "/" + bucket + "/" + srcKey;
		req.addHeader(new HTTPHeader("x-amz-copy-source", copySource));

		SimpleDateFormat rfc2822Fmt = new SimpleDateFormat("EEE, dd MMM yyyy HH:mm:ss Z (zzz)");
		String formattedDate = rfc2822Fmt.format(new Date());
		req.addHeader(new HTTPHeader("Date", formattedDate));

		String stringToSign = "PUT\n\n\n" + formattedDate + "\n" + "x-amz-copy-source:" + copySource + "\n" + "/" + bucket + "/" + destKey;
		req.addHeader(new HTTPHeader("Authorization", "AWS " + S3PolicyGenerator.AWS_ACCESS_KEY + ":" + S3PolicyGenerator.signString(stringToSign)));

		return req;
	}

	private static String generateURL(String method, String bucket, String key, long expiration) {
		expiration += System.currentTimeMillis();
		// stupid amazon, using seconds. bah.
		expiration /= 1000;
		String toSign = method + "\n\n\n" + expiration + "\n" + "/" + bucket + "/" + key;

		String signature = signAndUrlEncode(toSign);

		return "http://" + bucket + ".s3.amazonaws.com/" + key + "?AWSAccessKeyId=" + S3PolicyGenerator.AWS_ACCESS_KEY + "&Expires=" + expiration + "&Signature=" + signature;
	}

	static String signAndUrlEncode(String toSign) {
		String signature;
		try {
			signature = URLEncoder.encode(S3PolicyGenerator.signString(toSign), "UTF-8");
		} catch (UnsupportedEncodingException e) {
			throw new RuntimeException("Java doesn't know about UTF-8, so you're hosed");
		}
		return signature;
	}


	private HTTPRequest createRequest(HTTPMethod method, String url) {
		HTTPRequest req;
		try {
			req = new HTTPRequest(new URL(url), method);
		} catch (MalformedURLException e) {
			throw new RuntimeException("Your URL is booched", e);
		}

		req.getFetchOptions().doNotFollowRedirects().setDeadline(TIMEOUT_SECONDS);

		return req;
	}

	private boolean verifyRequest(int expectedCode, HTTPRequest req) {
		try {
			return verifyResponse(expectedCode, URLFetchServiceFactory.getURLFetchService().fetch(req));
		} catch (IOException e) {
			throw new RuntimeException("Performing URLFetch", e);
		}
	}

	private boolean verifyResponse(int expectedCode, HTTPResponse httpResponse) {
		boolean matches = httpResponse.getResponseCode() == expectedCode;
		if (!matches) {
			Logger.getLogger("S3").log(Level.SEVERE, "Got a " + httpResponse.getResponseCode() + " from Amazon instead of a " + expectedCode);
		}
		return matches;
	}


	@Override
	public AsyncS3Client newAsyncExistenceClient(final Series... series) {
		return new AbstractAsyncS3Client(206, series) {
			long combinedContentLength = -1L;

			@Override
			HTTPRequest createRequest(S3Location s3Location, String key) {
				return createExistsRequest(s3Location, key);
			}

			@Override
			public void handleResponses(Collection<HTTPResponse> rsps) {
				for(HTTPResponse rsp : rsps){
					long sizeFromHeader = getSizeFromHeader(rsp);
					combinedContentLength += sizeFromHeader;
				}
				super.handleResponses(rsps);
			}

			@Override
			public Map<String, Object> getAdditionalInfo() {
				HashMap<String, Object> info = new HashMap<String, Object>();
				info.put("studySize", combinedContentLength);
				return info;
			}
		};
	}

	@Override
	public AsyncS3Client newAsyncDeletionClient(final Series... series) {
		/*
		 * Check to ensure that any series that gets passed into here does
		 * not have a null S3Location object, because a null S3Location means
		 * that the series is not stored in S3 and does not need to be deleted.
		 */
		List<Series> validSeries = new ArrayList<Series>(series.length);
		for (Series currentSeries : series) {
			if (currentSeries.getS3Location() != null) {
				validSeries.add(currentSeries);
			}
		}
		Series[] seriesToDelete = new Series[validSeries.size()];
		validSeries.toArray(seriesToDelete);
		
		if (DAO.MIGRATION_MODE)
			throw new RuntimeException("No deletes for now, plz");
		return new AbstractAsyncS3Client(DELETE_RESPONSE_CODE, seriesToDelete) {
			@Override
			HTTPRequest createRequest(S3Location s3Location, String key) {
				return createDeleteRequest(s3Location, key);
			}
		};
	}

	@Override
	public AsyncS3Client newAsyncCopyClient(S3Location loc, List<Pair<String, String>> srcDestPairs) {
		List<HTTPRequest> copyReqs = Lists.newArrayList();
		for (Pair<String,String> p : srcDestPairs) {
			copyReqs.add(createCopyRequest(loc, p.first, p.second));
		}
		return new AbstractAsyncS3Client(200, copyReqs) {
			@Override
			HTTPRequest createRequest(S3Location s3Location, String key) {
				throw new RuntimeException("Nobody should call this, ever, since the requests are already made");
			}
		};
	}

	private static abstract class AbstractAsyncS3Client implements AsyncS3Client {
		protected boolean result = true;
		protected final int responseCode;

		public AbstractAsyncS3Client(int responseCode, Series... series) {
			this.responseCode = responseCode;
			List<HTTPRequest> reqs = Lists.newArrayList();

			makeRequests(reqs, series);

			AsyncS3Pool.instance.performRequests(this, reqs);
		}

		protected AbstractAsyncS3Client(int responseCode, List<HTTPRequest> reqs) {
			this.responseCode = responseCode;
			AsyncS3Pool.instance.performRequests(this, reqs);
		}

		protected void makeRequests(List<HTTPRequest> reqs, Series... series) {
			for (Series ser : series) {
				for (String key : ser.getAllUrls()) {
					reqs.add(createRequest(ser.getS3Location(), key));
				}
			}
		}

		abstract HTTPRequest createRequest(S3Location s3Location, String key);

		@Override
		public boolean waitFinalResult() {
			while (!isFinished()) {
				AsyncS3Pool.instance.churn(this, true);
			}
			return result;
		}

		@Override
		public boolean isFinished() {
			return AsyncS3Pool.instance.anyPending(this);
		}

		@Override
		public void handleResponses(Collection<HTTPResponse> rsps) {
			for (HTTPResponse rsp : rsps) {
				int resultCode = rsp.getResponseCode();
				debug("Response code " + resultCode);
				if (resultCode != responseCode) {
					String content = "NULL";
					if (rsp.getContent() != null) {
						content = new String(rsp.getContent());
					}
					if (resultCode == 500 || resultCode == 403) {
						throw new RuntimeException("Funkiness happened - got code " + resultCode + " expecting " + responseCode + "\n" + rsp.getFinalUrl()
								+ "\nBody Content:\n" + content);
					}
					warn("Expected " + responseCode + ", received " + resultCode + "\n" + rsp.getFinalUrl()
							+ "\nBody Content:\n" + content);
					result = false;
					AsyncS3Pool.instance.cancelPendingRequests(this);
					return;
				}
			}
		}

		@Override
		public Map<String, Object> getAdditionalInfo() {
			return new HashMap<String, Object>();
		}
	}

	static void warn(String msg) {
		Logger.getLogger("S3").log(Level.WARNING, msg);
	}

	static void info(String msg) {
		Logger.getLogger("S3").log(Level.INFO, msg);
	}

	static void debug(String msg) {
		Logger.getLogger("S3").log(Level.FINE, msg);
	}

}
